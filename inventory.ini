#Data Sources must start with the word "DataSource" followed by a name

#options specific to the scraping runtime script itself
[Scrape]
#Because actions will be done on the results of scraping
#should a data source decide to behave badly and return
#invalid/bad results for whatever reason we don't want
#downstream bad things to happen.  This number represents
#the number of attributes that must exist at a minimum.
#The number aligns with the output data in a resulting
#json file

safety_limit = 4500

[DataSource V]
class = V
command = /usr/bin/perl /path/to/v

[DataSource Satellite]
class = Satellite
username = 
password = 
url = 
min_days_reported_considered_active = 30

[DataSource SCCM]
class = SCCM
path = /path/to/sccm/win_info.csv 

[DataSource Lookup]
class = Lookup
depends = V, Satellite, SCCM, ZenossEnt, ZenossCore, ZenVsphere

#[DataSource Ping]
# class = Ping
# wait = 2
# count = 2
# depends = Lookup

[DataSource IP]
class = IP
depends = Lookup

[DataSource ZenossEnt]
class = Zen
url = 
username: 
password: 

[DataSource ZenossCore]
class = Zen
url = 
username: 
password: 

[DataSource ZenMom]
class = Zen
url = 
username: 
password: 

[DataSource ZenVsphere]
class = ZenVsphere
url = 
username:
password: 

